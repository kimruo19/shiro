<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copy Text Buttons</title>
    <style>
        button {
            margin: 5px;
        }

        body {
            background-color: grey;
            /* Light gray background */
            font-family: Arial, sans-serif;
            text-align: center;
        }

        button {
            margin: 10px;
            padding: 10px;
            font-size: 16px;
            background-color: grey;
            /* Light gray button background */
            border: 1px solid #aaa;
            /* Dark gray border */
            cursor: pointer;
        }

        button:hover {
            background-color: #ccc;
            /* Slightly darker background on hover */
        }
    </style>
</head>

<body>

    <button onclick="copyText(text1)">1A Supervised (KNN)</button>
    <button onclick=" copyText(text2)">1B Unsupervised (KMeans)</button>
    <button onclick="copyText(text3)">2 Naive Bayes (Binary Classification)</button>
    <button onclick="copyText(text4)">3 Overfitting (Polynomial Regression Model)</button>
    <button onclick="copyText(text5)">4 Linear Regression (Salary Prediction)</button>
    <button onclick="copyText(text6)">5 MultiClass Classification</button>
    <button onclick="copyText(text7)">6 K-Means Clustering</button>
    <button onclick="copyText(text8)">7 Decision Tree</button>
    <button onclick="copyText(text9)">8 Hierarchical Clustering</button>
    
    
    <p id="copiedMsg"></p>
    <script>
        var text1 = `#Pract 1 :1A Supervised (KNN)

# 1A Supervised learning (KNN)

# Import necessary Libraries
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score

# Load the Iris Dataset
iris = load_iris()

# Split the dataset into features and target
X,Y = iris.data,iris.target

# Split the dataset into training and testing set
X_Train,X_Test,Y_Train,Y_Test = train_test_split(X,Y,test_size= 0.2,random_state=42)

# Initialize a KNearest Classifier
knn_cls = KNeighborsClassifier(n_neighbors = 3)

# Train the model on the training data
knn_cls.fit(X_Train,Y_Train)

# Make prediction on test data
pred = knn_cls.predict(X_Test)

# Evaluate the model accuracy and classification report
acc = accuracy_score(Y_Test,pred)
cl_report = classification_report(Y_Test,pred)
print("\n*****************")
print("Accuracy :",acc)
print("*****************")
print("Classification Report :",cl_report)
print("*****************")
print("Shipra Jana")
print("KFMSCIT014")
print("****************")
    `;
    
        var text2 = `#Practical 1b - 1B Unsupervised (KMeans)

        # 1B Unsupervised Learning (Kmeans)

#Import necessary libraries
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

#Load the Iris dataset
iris = load_iris()

#Split the dataset into features and target
X,Y = iris.data,iris.target

#Initialize the KMeans model with 3 clusters and a random seed
Km = KMeans(n_clusters = 3,random_state=40)

#Fit the KMeans model to the data
Km.fit(X)

#Get the cluster labels assigned by the KMeans algorithm
cluster_label = Km.labels_

# Plot the clustered data points
plt.scatter(X[:,0],X[:,1],c=cluster_label,cmap='viridis')
plt.title(" Shipra Jana 014 \n Unsupervised - KMeans")
plt.show()

`;

        var text3 = ` #Pract 2 - 2 Naive Bayes (Binary Classification)

        # 2 Naive Bayes (Binary Classification)

#Import necessary Libraries
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
from sklearn import metrics
#Load the Iris dataset
iris = load_iris()

#Split the dataset into features and target
X = iris.data
Y = iris.target

#Split the dataset into training and testing set
X_Train,X_Test,Y_Train,Y_Test = train_test_split(X,Y,test_size= 0.2,random_state=42)

#Training the model on training set
gnb = GaussianNB()
gnb.fit(X_Train, Y_Train)

# making predictions on the testing set
y_pred = gnb.predict(X_Test)

# comparing actual response values (y_test) with predicted response values (y_pred)
acc = metrics.accuracy_score(Y_Test, y_pred) * 100
clr_report = metrics.classification_report(Y_Test, y_pred)
print("\n**********************************************")
print("Gaussian Naive Bayes Model Accuracy :", acc)
print("***********************************************")
print("Classification Report :", clr_report)
print("***********************************************")
print("Shipra Jana")
print("KFMSCIT014")
print("***********************************************")

`;

        var text4 = ` # 3 Overfitting (Polynomial Regression Model)

        # 3 Overfitting in Polynomial Regression Model

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generate synthetic data
np.random.seed(0)
X = np.linspace(0, 5, 100).reshape(-1, 1)
Y = 2 * np.sin(X) + np.random.normal(0, 0.5, size=X.shape)

# Split data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Define a function to fit polynomial regression models of varying degrees
def fit_polynomial(X_train, Y_train, X_test, Y_test, degree):
 poly = PolynomialFeatures(degree=degree)
 X_train_poly = poly.fit_transform(X_train)
 X_test_poly = poly.transform(X_test)
 model = LinearRegression()
 model.fit(X_train_poly, Y_train)
 train_rmse = np.sqrt(mean_squared_error(Y_train, model.predict(X_train_poly)))
 test_rmse = np.sqrt(mean_squared_error(Y_test, model.predict(X_test_poly)))
 return model, train_rmse, test_rmse

# Fit polynomial regression models of varying degrees
degrees = [1, 3, 10]
models = []
train_rmse_values = []
test_rmse_values = []
for degree in degrees:
 model, train_rmse, test_rmse = fit_polynomial(X_train, Y_train, X_test, Y_test, degree)
 models.append(model)
 train_rmse_values.append(train_rmse)
 test_rmse_values.append(test_rmse)

 # Plot the results
 plt.figure(figsize=(10, 6))
 plt.scatter(X_train, Y_train, color='blue', label='Training Data')
 plt.scatter(X_test, Y_test, color='green', label='Testing Data')
 x_values = np.linspace(0, 5, 100).reshape(-1, 1)
 for i, model in enumerate(models):
     y_values = model.predict(PolynomialFeatures(degree=degrees[i]).fit_transform(x_values))
     plt.plot(x_values, y_values, label=f'Degree {degrees[i]}')
 plt.title('Shipra Jana 014 \n Polynomial Regression with Different Degrees')
 plt.xlabel('X')
 plt.ylabel('Y')
 plt.legend()
 plt.show()
 
`;

        var text5 = `# 4 Linear Regression (Salary Prediction)

# Linear Regresssion Analysis for Salary Prediction

#Import necessary Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,r2_score

#Load the IrisDataset
df = pd.read_csv("Salary_Data.csv")
df.head()

#extract
x=df['YearsExperience'].values.reshape(-1,1)
y=df['Salary'].values

#Split the data
X_train,X_test , Y_train , Y_test = train_test_split(x,y,test_size=0.2,random_state=42)
r1 = LinearRegression()
r1.fit(X_train,Y_train)
y_pred = r1.predict(X_test)
print(y_pred)
MSE = mean_squared_error(Y_test,y_pred)
r2 = r2_score(Y_test,y_pred)
print("\n***************************")
print('MSE',MSE)
print("\n***************************")
print('r2' , r2)
print("\n***************************")
print("Shipra Jana")
print("KFMSCIT014")
print("****************************")
        
  `;
  
        var text6 = ` # 5 MultiClass Classification
        # 5 Evaluation of Multiclass Classification Model Performance

#Import necessary Libraries
import pandas as pd
from sklearn.svm import SVC
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
#Load the iris dataset
data = pd.read_csv('iris.csv')

#Split the dataset
X = data.iloc[:, :-1].values
Y = data.iloc[:, -1].values
#print(X)
#print(Y)

#Split the dataset into training and testing set
X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size = 0.2, random_state = 42)

#Model
model = SVC()

#Train the model on the training data
model.fit(X_train, Y_train)

#Make prediction on test data
Y_pred = model.predict(X_test)

#Evaluate the model accuracy precision recall and f1 score
accuracy = metrics.accuracy_score(Y_test, Y_pred) * 100
precision = metrics.precision_score(Y_test,Y_pred,average='macro') * 100
re = metrics.recall_score(Y_test, Y_pred, average='macro') * 100
fe = metrics.f1_score(Y_test, Y_pred, average='macro') * 100
clr_report = metrics.classification_report(Y_test, Y_pred)
print("\n*******************************")
print("Accuracy :", accuracy)
print("*******************************")
print("Precision :", precision)
print("*******************************")
print("Recall :", re)
print("*******************************")
print("F1 Score :", fe)
print("*********************************************************************************")
print("Classification Report :", clr_report)
print("*****************")
print("Shipra Jana")
print("KFMSCIT014")
print("*****************")

`;

        var text7 = `# 6 K-Means Clustering

        # 6 K â€“ Means Clustering

#Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

#Sample data representing Flower Location
data = pd.DataFrame({'Income':[25000,50000,75000,100000,125000,150000,175000,200000],
 'Spending': [15000,25000,35000,45000,55000,65000,75000,85000]})

#No. of Clusters i.e. k
k = 3

#Initialize the KMeans model with k clusters
kmeans = KMeans(n_clusters=k)

#Fit(Train) the KMeans model to the data
kmeans.fit(data)

#Predict the cluster labels for each data point
clusters_labels = kmeans.predict(data)

#Plot the clustered data points
plt.scatter(data['Income'],data['Spending'],c=clusters_labels)
plt.xlabel('X Coordinate')
plt.ylabel('Y Coordinate')
plt.title('Shipra Jana 014 \n K-Means Clustering(k='+str(k)+')')
plt.show()



    # another code
    
    #Import all the libraries
import numpy as np

#Sample data representing flower Location
data = np.array([[1,2],[1.5,1.8],[5,8],[8,8],[1,0.5],[7,9],[9,10],[5.5,8.5]])

#number of clusters i.e k
k = 3

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=k)
kmeans.fit(data)

clusters_labels = kmeans.predict(data)

import matplotlib.pyplot as plt

plt.scatter(data[:,0],data[:,1],c=clusters_labels)
plt.xlabel('X Coordinate')
plt.ylabel('Y Coordinate')
plt.title('kmean clusterint(k='+str(k)+')')
plt.show()

`;

var text8 = `# 7 Decision Tree

        # Decision Tree

#Import necessary Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#Reading the database
data = pd.read_csv('iris.csv')
print("****************************************************************")
print(" IRIS DATASET ")
print("****************************************************************")
print(data.head())
print("****************************************************************")
#Assuming the target variable is in a column named 'target'
X = data.drop('species', axis=1)
y = data['species']

#Split the dataset into training and testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Initialize the Decision Tree model
model = DecisionTreeClassifier()

#Fit the model on the training data
model.fit(X_train, y_train)

#Make predictions on the testing data
y_pred = model.predict(X_test)

#Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print("\n*****************")
print("Shipra Jana")
print("KFMSCIT014")
print("*****************")
# Visualize and interpret the generated decision tree
plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, feature_names=X.columns, class_names=y.unique().astype(str))
plt.title("Shipra Jana 014 \n\n Decision Tree Visualization")
plt.show()

`;

var text9 = `# 8 Hierarchical Clustering

        # Evaluation of Hierarchical Clustering Performance

#Import necessary Libraries
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score,completeness_score

#Sample data points
data=np.array([[1,1],[5,5],[8,8],[1,0],[5,4],[8,1]])

#Define linkage criterion for merging clusters
linkage='ward'

#Initialize and fit the Agglomerative Clustering model
model=AgglomerativeClustering(n_clusters=3,linkage=linkage)

#Fit the Agglomerative Clustering model to the data
model.fit(data)

#Predicted cluster labels
cluster_labels=model.labels_

#Calculate silhouette score to evaluate clustering performance
s=silhouette_score(data,cluster_labels)
print("**********************")
print(s)

#Calculate completeness score if applicable (based on linkage criterion)
g=None
if( linkage=='ward' and g is not None):
 c=completeness_score(g,cluster_labels)
 print(c)
else:
 print("not applicable")
print("**********************")
print("Shipra Jana")
print("KFMSCIT014")
print("**********************")

`;


function copyText(text) {
    navigator.clipboard.writeText(text).then(function () {
        document.getElementById('copiedMsg').innerHTML = "Text Copied"
    }).catch(function (err) {
        console.error('Unable to copy text', err);
    });
}
</script>

</body>

</html>
