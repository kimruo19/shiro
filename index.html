<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copy Text Buttons</title>
    <style>
        button {
            margin: 5px;
        }

        body {
            background-color: black;
            /* Light gray background */
            font-family: Arial, sans-serif;
            text-align: center;
        }

        button {
            margin: 10px;
            padding: 10px;
            font-size: 16px;
            background-color: DimGray;
            /* Light gray button background */
            border: 1px solid #560b0b;
            /* Dark gray border */
            cursor: pointer;
        }

        button:hover {
            background-color: #ccc;
          /* Slightly darker background on hover */
        }

    </style>
</head>

<body>

    <button onclick="copyText(text1)">1 TEXT to SPEECH</button>
    <button onclick="copyText(text2)">2 Speech recognition </button>
    <button onclick="copyText(text3)">3 Wordcloud </button>
    <button onclick="copyText(text4)">4 NLP libraries perform on any Indian language </button>
    <button onclick="copyText(text5)">5.a	Implementation of lemmatization		</button>
    <button onclick="copyText(text6)">5.b Implementation of Stemming</button>
    <button onclick="copyText(text7)">6.a Wordnet synsets, definitions, examples, antonyms</button>
    <button onclick="copyText(text8)">6.B	Study of lemmas, hyponyms, hypernyms, entailments</button>
    <button onclick="copyText(text9)">6.c find synonym and antonym of the word using “active” using Wordnet</button>
    <button onclick="copyText(text10)">7.a Implementation Of WSD</button>
    <button onclick="copyText(text11)">7.b Visualization  Of  WSD		</button>
    <button onclick="copyText(text12)">8.a Implementation of Treebank (Penn Bank)</button>
    <button onclick="copyText(text13)">8.B	Implementation of Treebank (Parse Tree)		</button>
    <button onclick="copyText(text14)">9.a Demonstrate word + POS tagging using lexical Tagging</button>
    <button onclick="copyText(text15)">9.B	Demonstrate Concept of Shallow Parsing		</button>
    <button onclick="copyText(text16)">10.a Demonstrate spacy</button>
    <button onclick="copyText(text17)">10.b Demonstrate Gensim</button>
    <button onclick="copyText(text18)">10.c Language implementation using  Gensim</button>
    <button onclick="copyText(text19)">11 Implement google trans module multi Lingual NLP </button>
    
    
    <p id="copiedMsg"></p>
    <script>
        var text1 = `# Practical1:TEXT to SPEECH

Step 1: open cmd > enter commands
	pip install playsound==1.2.2
	pip install gTTS

from gtts import gTTS
from playsound import playsound

mytext = "Sanjana Shahi"
language = "en"

tts = gTTS(text=mytext, lang=language, slow=True)

filename = "myfile1.mp3"
tts.save(filename)

print("Playing audio...")
playsound(filename)
    `;


        var text2 = `# 2p speech recogonization 
        import speech_recognition as sr
import pyttsx3
recognizer = sr.Recognizer()
engine = pyttsx3.init()
def speak(text):
 print("Bot:", text)
 engine.say(text)
 engine.runAndWait()
def process_nlp(text):
 text = text.lower()
 if "hello" in text or "hi" in text:
 return "Hello! How can I help you today?"
 elif "your name" in text:
 return "I am your Python voice assistant."
 elif "how are you" in text:
 return "I'm just a program, but I'm functioning as expected!"
 elif "bye" in text:
 return "Goodbye! Have a nice day!"
 else:
return "Sorry, I didn't understand that."
def listen_and_respond():
 with sr.Microphone() as source:
 print("Listening... (say something)")
 audio = recognizer.listen(source)
 try:
 user_input = recognizer.recognize_google(audio)
 print("You said:", user_input)
 response = process_nlp(user_input)
 speak(response)
 except sr.UnknownValueError:
 speak("Sorry, I couldn't understand.")
 except sr.RequestError:
 speak("Sorry, there was an error with the speech service.")
listen_and_respond()
`;


        var text3 = ` #3Practical NO: 3 Word Cloud

Step 1: open cmd > enter commands
	pip install wordcloud

from wordcloud import WordCloud
import matplotlib.pyplot as plt
text="A dream does ;not become reality through magic; it takes sweat, determination, and hard work." "I'm a great believer In luck and T find the harder I work, the more I have of it." "Doing the best ai this moment puts you in the best place for the next moment" "Hard work beats alent if talent doesn't work hard"
wordcloud= WordCloud(width=800, height=800, background_color="white", min_font_size=10).generate(text)
plt.figure(figsize=(8,8))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

`;


        var text4 = ` # Prac4:Using NLP libraries perform on any Indian language

Step 1: open cmd > enter commands
pip install playsound

from gtts import gTTS
from playsound import playsound

print("choose language:\n1.English\n2.Marathi")
lang_choice = input("enter either 1 or 2 : ")

if lang_choice == "1":
    lang = 'en'
    reminder = input("Enter your reminder message in English: ")
elif lang_choice == "2":
    lang = 'mr'
    reminder = input("मराठीत तुमचा स्मरण संदेश टाइप कराः ")
else:
    print("Invalid choice. Defaulting to English.")
    lang = 'en'
    reminder = "This is a default reminder."

tts = gTTS(text=reminder, lang=lang)
filename = "voice_reminder.mp3"
tts.save(filename)

print("Playing your reminder...")
playsound(filename)

`;



        var text5 = `#Pract5A-Lemmatization

pip uninstall pydantic -y
pip install pydantic==1.10.12
pip install spacy==3.7.2
python -m spacy download en_core_web_sm

import spacy
nlp = spacy.load("en_core_web_sm")
text = "She was running with better prospects and had children"
doc = nlp(text)
for token in doc:
    print(f"{token.text} = {token.lemma_}")
         
  `;

  
        var text6 = ` #Practical5B-Stemming

from nltk.stem import PorterStemmer
stemmer = PorterStemmer()
word = {'running','studies','happiness','easily','adjustment'}
for w in word:
  print(f"{w} = {stemmer.stem(w)}")
        

`;


        var text7 = `# Pract.6A&BStudy of Wordnet dictionary with methods such as synsets, definitions, examples, antonyms & Study of lemmas, hyponyms, hypernyms, entailments 

import nltk
from nltk.corpus import wordnet as wn
nltk.download('wordnet')
nltk.download('omw-1.4')
syn=wn.synset('computer.n.01')
print("Synsets for 'computer':", syn.name())
print("Definition", syn.definition())
print("Examples", syn.examples())
print("Lemmas", syn.lemmas())
print("Hyponyms", syn.hyponyms())
print("Hypernyms", syn.hypernyms())
print("Root Hypernyms", syn.root_hypernyms())
antonyms=[]
for lemma in syn.lemmas():
 antonyms.extend(lemma.antonyms())
print("Antonyms", antonyms)

`;


        var text8 = `# Pract.6A&BStudy of Wordnet dictionary with methods such as synsets, definitions, examples, antonyms & Study of lemmas, hyponyms, hypernyms, entailments 

import nltk
from nltk.corpus import wordnet as wn
nltk.download('wordnet')
nltk.download('omw-1.4')
syn=wn.synset('computer.n.01')
print("Synsets for 'computer':", syn.name())
print("Definition", syn.definition())
print("Examples", syn.examples())
print("Lemmas", syn.lemmas())
print("Hyponyms", syn.hyponyms())
print("Hypernyms", syn.hypernyms())
print("Root Hypernyms", syn.root_hypernyms())
antonyms=[]
for lemma in syn.lemmas():
 antonyms.extend(lemma.antonyms())
print("Antonyms", antonyms)

`;


        var text9 = `# P6-C:Write a program using python to find synonym and antonym of the word using “active” using Wordnet

import nltk
from nltk.corpus import wordnet as wn

nltk.download('wordnet')

syn = wn.synset('dance.v.01')
print("Synset:", syn.name())
print("Definition:", syn.definition())

entailments = syn.entailments()
for e in entailments:
    print(e.name(), ":", e.definition())



`;

        var text10 = `#Practicalno-7A Implementation Of WSD

import nltk
nltk.download('punkt_tab')
nltk.download('wordnet')
from nltk.corpus import wordnet as wn
from nltk import word_tokenize
import string

def simple_lesk(word, sentence):
    tokens = [w.lower() for w in word_tokenize(sentence)]
    tokens = [w for w in tokens if w not in string.punctuation]
    best, max_overlap = None, 0
    for sense in wn.synsets(word):
        sig = word_tokenize(sense.definition().lower())
        for ex in sense.examples():
            sig += word_tokenize(ex.lower())
        sig += [l.replace('_',' ') for l in sense.lemma_names()]
        sig = [w for w in sig if w not in string.punctuation]
        overlap = len(set(sig).intersection(tokens))
        if overlap > max_overlap:
            best, max_overlap = sense, overlap
    return best

examples = [
    ("bank", "He sat on the bank of the river."),
    ("bank", "She went to the bank to deposit money."),
    ("plant", "The factory is a large chemical plant."),
    ("plant", "Please water the plant on the balcony.")
]

for target, sent in examples:
    sense = simple_lesk(target, sent)
    print(target, ":", sense, "->", sense.definition() if sense else "None")



`;


        var text11 = `# Practical-7B Visualization Of WSD  

import nltk
from nltk.corpus import wordnet as wn
from nltk.tokenize import word_tokenize
import string
import matplotlib.pyplot as plt

nltk.download('punkt')
nltk.download('wordnet')

def plot_wsd(word, sentence):
    tokens = [w.lower() for w in word_tokenize(sentence) if w not in string.punctuation]
    senses, scores = [], []

    for sense in wn.synsets(word):
        sig = word_tokenize(sense.definition().lower())

        for ex in sense.examples():
            sig += word_tokenize(ex.lower())

        sig += [l.replace('_',' ') for l in sense.lemma_names()]
        sig = [w for w in sig if w not in string.punctuation]

        overlap = len(set(sig).intersection(tokens))
        senses.append(sense.name())
        scores.append(overlap)

    plt.figure(figsize=(8,4))
    plt.barh(senses, scores)
    plt.xlabel("Overlap Score")
    plt.ylabel("Senses")
    plt.title(f"WSD Overlaps for '{word}' in: {sentence}")
    plt.show()

plot_wsd("bank", "He sat on the bank of the river.")

`;


        var text12 = `# Practical8A:Implementation of Treebank (Penn Bank)

import nltk
from nltk.corpus import treebank
nltk.download('treebank')
 
def main():
  # Load the tagged sentences and words from the treebank corpus
  tagged_sentences = treebank.tagged_sents()
  tagged_words = treebank.tagged_words()
  #Print the first tagged sentence
  print ("First tagged sentence:")
  print(tagged_sentences [0])
  #Print the first 10 tagged words
  print ("\nFirst 10 tagged words.")
  print(tagged_words[:10])
 
if name == "main":
  main()

`;



        var text13 = `# Practical8b:Implementation Parse Tree

import spacy
from spacy import displacy

nlp = spacy.load("en_core_web_sm")

text = "Emma visited Tommy in his room while Nero played his lyre."
doc = nlp(text)

# Show in browser
displacy.serve(doc, style="dep")

# Save as SVG
svg = displacy.render(doc, style="dep")
with open("dep_tree.svg", "w", encoding="utf-8") as f:
    f.write(svg)

print("Dependency tree saved as dep_tree.svg")


open in chrome http://localhost:5000 you will see the parse Tree

`;


        var text14 = `#Pract:09(A)Demonstrate word+POS tagging using lexical Tagging

import nltk
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger_eng')

sentence = "He drives very carefully under the table."

# Tokenize the sentence into words
words = nltk.word_tokenize(sentence)

# Part-of-speech tagging
pos_tags = nltk.pos_tag(words)

print("Lexicon / POS Tags:")
for word, tag in pos_tags:
    print(f"{word} -> {tag}")

`;


        var text15 = `#Practical 09(B)Demonstrate Concept of Shallow Parsing

import nltk

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

sentence = "He drives very carefully under the table."

words = nltk.word_tokenize(sentence)

pos_tags = nltk.pos_tag(words)

grammar = "NP: {<DT>?<JJ>*<NN|PRP>+}"

cp = nltk.RegexpParser(grammar)

tree = cp.parse(pos_tags)

print("\nShallow Parsing / Chunking Result:")
print(tree)
tree.pretty_print()

`;


        var text16 = `#Practical10(A)Demonstrate spacy(pos tagging and lemmatization)

import spacy
from spacy import displacy

# Load English model
nlp = spacy.load("en_core_web_sm")

text = "She was running with a better prospects and had children"
doc = nlp(text)

# Print tokens, POS tags, and lemmas
print("Token -> POS -> Lemma")
for token in doc:
    print(f"{token.text} -> {token.pos_} -> {token.lemma_}")

# Serve dependency diagram on localhost:5000
# Opens the diagram in your browser at http://localhost:5000
displacy.serve(doc, style="dep")

`;


        var text17 = `#Practical10(B)Demonstrate Gensim

# Step 1: Install and Import Libraries
pip install gensim matplotlib scikit-learn

from gensim.models import Word2Vec
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt


sentences = [
    ["students", "love", "python"],
    ["teachers", "guide", "students"],
    ["college", "life", "is", "fun"],
    ["friends", "enjoy", "festivals"],
    ["learning", "never", "ends"],
    ["python", "is", "interesting"],
    ["study", "hard", "for", "success"],
    ["teachers", "help", "in", "learning"],
    ["campus", "events", "are", "memorable"],
]

model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=1)

words = list(model.wv.key_to_index.keys())
word_vectors = model.wv[words]

tsne = TSNE(n_components=2, random_state=42, perplexity=5)
vectors_2d = tsne.fit_transform(word_vectors)

plt.figure(figsize=(10, 6))
plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1])

for i, word in enumerate(words):
    plt.annotate(word, xy=(vectors_2d[i, 0], vectors_2d[i, 1]), fontsize=10, color='blue')

plt.title("Gensim Word2Vec Visualization (College Life Example)")
plt.xlabel("t-SNE Dimension 1")
plt.ylabel("t-SNE Dimension 2")
plt.grid(True)
plt.show()

`;


        var text18 = `#
        Practical10(C)Language implementation using  Gensim

from gensim.models import Word2Vec
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

sentences = [
    ["الطلاب", "يكرهون", "بايثون"],
    ["هو", "يرشد", "ها"],
    ["الحياة", "جميلة"],
    ["هي", "تستمتع", "بالنوم"]
]

model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=1)

words = list(model.wv.key_to_index.keys())
word_vectors = model.wv[words]

tsne = TSNE(n_components=2, random_state=42, perplexity=5)
vectors_2d = tsne.fit_transform(word_vectors)

plt.figure(figsize=(10, 6))
plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1])

for i, word in enumerate(words):
    plt.annotate(word, xy=(vectors_2d[i, 0], vectors_2d[i, 1]), fontsize=10, color='blue')

plt.title("Gensim Word2Vec Visualization (College Life Example)")
plt.xlabel("t-SNE Dimension 1")
plt.ylabel("t-SNE Dimension 2")
plt.grid(True)
plt.show()

`;


        var text19 = `# Practical11google trans module(multi Lingual NLP )

install: pip install playsound
         pip install googletrans==4.0.0-rc1
         or pip install googletrans==4.0.0-rc1 gtts


from googletrans import Translator
from gtts import gTTS
from playsound import playsound

translator = Translator()

text = "Education gives power and confidence to everyone."

translations = {
    "Hindi": "hi",
    "Urdu": "ur",
    "Marathi": "mr",
    "Gujarati": "gu",
    "Chinese": "zh-cn"
}

print("Original Text:", text)
print("-" * 60)

for lang, code in translations.items():
    translated_text = translator.translate(text, dest=code).text
    print(f"{lang}: {translated_text}")

    # Generate audio
    tts = gTTS(text=translated_text, lang=code, slow=False)
    filename = f"{lang}_translation.mp3"
    tts.save(filename)

    # Play audio in IDLE
    print(f"Playing {lang} translation...")
    playsound(filename)

`;


function copyText(text) {
    navigator.clipboard.writeText(text).then(function () {
        document.getElementById('copiedMsg').innerHTML = "Text Copied"
    }).catch(function (err) {
        console.error('Unable to copy text', err);
    });
}
</script>

</body>

</html>
