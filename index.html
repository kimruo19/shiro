            <!DOCTYPE html>
            <html lang="en">

            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>Copy Text Buttons</title>
                <style>
                    button {
                        margin: 5px;
                    }

                    body {
                        background-color: black;
                        /* Light gray background */
                        font-family: Arial, sans-serif;
                        text-align: center;
                    }

                    button {
                        margin: 10px;
                        padding: 10px;
                        font-size: 16px;
                        background-color: DimGray;
                        /* Light gray button background */
                        border: 1px solid #560b0b;
                        /* Dark gray border */
                        cursor: pointer;
                    }

                    button:hover {
                        background-color: #ccc;
                    /* Slightly darker background on hover */
                    }

                </style>
            </head>

            <body>

                <button onclick="copyText(text1)"> 1(A)  Real-Time Processing and Object Detection</button>
                <button onclick="copyText(text2)"> 1(B)	 Gray Scale Conversion</button>
                <button onclick="copyText(text3)"> 1(C)  Edge detection</button>
                <button onclick="copyText(text4)"> 1(D)	Face detection</button>
                <button onclick="copyText(text5)"> 1(E)	Image Cropping and Mouse Events </button>
                <button onclick="copyText(text6)"> 1(F)	Save the image</button>
                <button onclick="copyText(text7)"> 2 - Multicolor Object Tracking </button>
                <button onclick="copyText(text8)"> 3 - Real Time Doc Scanners</button>
                <button onclick="copyText(text9)"> 4 - Virtual drawing using finger tracking (only green and blue)</button>
                <button onclick="copyText(text10)">5 (A) Multi-Face and object Detection(Group Photo-classify girls and boys )</button>
                <button onclick="copyText(text11)">5 (B) Group Photo-with Person name Detection</button>
                <button onclick="copyText(text12)">5 (C)  Detect and label common object(like eraser,scale,pencil) in a static image using opencv</button>
                <button onclick="copyText(text13)">6 - Write a program use PYOpenGL and GLUT TO draw simple triangle</button>
                <button onclick="copyText(text14)">7 - Write a program use PYOpenGL and GLUT TO draw simple square</button>
                <button onclick="copyText(text15)">8 - Write a program with PYOpenGL to draw 3d cubes</button>
                
                
                <p id="copiedMsg"></p>
                <script>
                    var text1 = `#1A_Image Capture Real-Time Processing and Object Detection

cmd- pip install opencv-python 

import cv2

img = cv2.imread("input.png")   


if img is None:
    print("Image not found!")
else:
    cv2.imshow("Captured Image", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


                `;


                    var text2 = `# 1B_GrayScaleConversion

cmd: pip install opencv-python 

import cv2
img = cv2.imread("input.png")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
cv2.imshow("Original Image", img)
cv2.imshow("Gray Image", gray)
cv2.waitKey(0)
cv2.destroyAllWindows()

            `;


                    var text3 = ` #1C_Edge detection

cmd: pip install opencv-python

import cv2

# Load image
img = cv2.imread("input.png")

# Convert to grayscale (edge detection works on gray images)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply Canny Edge Detection
edges = cv2.Canny(gray, 100, 200)

# Display results
cv2.imshow("Original Image", img)
cv2.imshow("Gray Image", gray)
cv2.imshow("Edge Detection", edges)

cv2.waitKey(0)
cv2.destroyAllWindows()


            `;


                    var text4 = ` # 1D_Face detection

cmd : pip install opencv-python

import cv2

# Load image
img = cv2.imread("single.jpg")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Load Haar cascade using OpenCV's built-in path
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

print("Cascade loaded:", face_cascade.empty())  # Should print False

faces = face_cascade.detectMultiScale(gray, 1.3, 5)

for (x, y, w, h) in faces:
    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)

cv2.imshow("Face Detection", img)
cv2.waitKey(0)
cv2.destroyAllWindows()


            `;



                    var text5 = `#1E_ImageCropping & Mouse Events

cmd: pip install opencv-python

import cv2

# Load image
img = cv2.imread("single.jpg")

# Function to crop on mouse click
def crop(event, x, y, flags, param):
    global pt1, pt2, cropped
    if event == cv2.EVENT_LBUTTONDOWN:
        pt1 = (x, y)
    elif event == cv2.EVENT_LBUTTONUP:
        pt2 = (x, y)
        cropped = img[pt1[1]:pt2[1], pt1[0]:pt2[0]]
        cv2.imshow("Cropped Image", cropped)

# Initialize
pt1 = pt2 = (0,0)
cropped = None

cv2.namedWindow("Image")
cv2.setMouseCallback("Image", crop)

cv2.imshow("Image", img)
cv2.waitKey(0)
cv2.destroyAllWindows()



            `;


                    var text6 = ` #1F_Save Cropped image

cmd: install opencv-python

import cv2
# Load image
img = cv2.imread("single.jpg")

# Function to crop and save on mouse
def crop(event, x, y, flags, param):
    global pt1, pt2, cropped
    if event == cv2.EVENT_LBUTTONDOWN:
        pt1 = (x, y)
    elif event == cv2.EVENT_LBUTTONUP:
        pt2 = (x, y)
        cropped = img[pt1[1]:pt2[1], pt1[0]:pt2[0]]
        cv2.imshow("Cropped Image", cropped)
        cv2.imwrite("cropped_image.png", cropped)  # Save automatically
        print("Cropped image saved as 'cropped_image.png'")

# Initialize
pt1 = pt2 = (0,0)
cropped = None

cv2.namedWindow("Image")
cv2.setMouseCallback("Image", crop)

cv2.imshow("Image", img)
cv2.waitKey(0)
cv2.destroyAllWindows()

                    

            `;


                    var text7 = `# 2_MulticlrObjectTracking

cmd: pip install opencv-python

import cv2
import numpy as np

# Load image
img = cv2.imread("person.jpg")

# Convert to HSV color space (better for color detection)
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

# Define color ranges in HSV
# Example: Red, Green, Blue
colors = {
    "Red": ([0, 120, 70], [10, 255, 255]),
    "Green": ([36, 50, 70], [89, 255, 255]),
    "Blue": ([94, 80, 2], [126, 255, 255])
}

# Detect and mark each color
for color_name, (lower, upper) in colors.items():
    lower = np.array(lower)
    upper = np.array(upper)
    
    # Create mask for this color
    mask = cv2.inRange(hsv, lower, upper)
    
    # Find contours
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 500:  # filter small areas
            x, y, w, h = cv2.boundingRect(cnt)
            cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)
            cv2.putText(img, color_name, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)

# Show result
cv2.imshow("Multicolor Tracking", img)
cv2.waitKey(0)
cv2.destroyAllWindows()


            `;


                    var text8 = `# 3_RealTimeDocScanners

cmd: pip install opencv-python 

import cv2
import numpy as np
import os
import datetime
import time
 
# Create save folder if it doesn't exist
SAVE_DIR = "scanned_documents"
os.makedirs(SAVE_DIR, exist_ok=True)
 
# Camera setup
cap = cv2.VideoCapture(0)
cap.set(3, 640)
cap.set(4, 480)
 
print("Hold your book clearly in the frame")
print("ESC to exit, 'm' to manually crop with mouse")
 
drawing = False
manual_pts = []
last_auto_save_time = 0
AUTO_SAVE_INTERVAL = 5  # seconds between auto-saves
 
def reorder_points(pts):
    pts = pts.reshape((4, 2))
    new_pts = np.zeros((4, 2), dtype=np.float32)
    add = pts.sum(1)
    diff = np.diff(pts, axis=1)
    new_pts[0] = pts[np.argmin(add)]
    new_pts[2] = pts[np.argmax(add)]
    new_pts[1] = pts[np.argmin(diff)]
    new_pts[3] = pts[np.argmax(diff)]
    return new_pts
 
def get_warp(image, points, w=600, h=800):
    points = reorder_points(points)
    dest = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)
    matrix = cv2.getPerspectiveTransform(points, dest)
    warped = cv2.warpPerspective(image, matrix, (w, h))
    return warped
 
def draw_manual(event, x, y, flags, param):
    global drawing, manual_pts
    if event == cv2.EVENT_LBUTTONDOWN:
        drawing = True
        manual_pts = [(x, y)]
    elif event == cv2.EVENT_LBUTTONUP:
        drawing = False
        manual_pts.append((x, y))
 
while True:
    ret, frame = cap.read()
    if not ret:
        break
 
    original = frame.copy()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 1)
 
    # More robust edge detection using adaptive threshold
    thresh = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        11, 2)
    edges = cv2.Canny(thresh, 50, 150)
 
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)
 
    doc_contour = None
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area < 15000 or area > frame.shape[0] * frame.shape[1] * 0.9:
            continue
        peri = cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
        if len(approx) == 4:
            doc_contour = approx
            break
 
    debug = frame.copy()
    for cnt in contours:
        if cv2.contourArea(cnt) > 15000:
            cv2.drawContours(debug, [cnt], -1, (255, 0, 0), 2)
 
    if doc_contour is not None:
        cv2.drawContours(debug, [doc_contour], -1, (0, 255, 0), 3)
        warped = get_warp(original, doc_contour)
 
        # Post-warp thresholding for cleaner scan
        gray_warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)
        gray_warped = cv2.GaussianBlur(gray_warped, (5, 5), 0)
        _, scanned = cv2.threshold(gray_warped, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
 
        cv2.imshow("Scanned", scanned)
 
        # Auto-save if enough time has passed
        current_time = time.time()
        if current_time - last_auto_save_time > AUTO_SAVE_INTERVAL:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            file_name = os.path.join(SAVE_DIR, f"auto_scan_{timestamp}.png")
            cv2.imwrite(file_name, scanned)
            print(f"[AUTO-SAVE] Document saved as {file_name}")
            last_auto_save_time = current_time
 
    cv2.imshow("Detected Contours", debug)
 
    # Check for manual crop
    if len(manual_pts) == 2:
        x1, y1 = manual_pts[0]
        x2, y2 = manual_pts[1]
        x_start, x_end = sorted([x1, x2])
        y_start, y_end = sorted([y1, y2])
        manual_crop = original[y_start:y_end, x_start:x_end]
        if manual_crop.shape[0] > 0 and manual_crop.shape[1] > 0:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            manual_file = os.path.join(SAVE_DIR, f"manual_scan_{timestamp}.png")
            cv2.imshow("Manual Crop", manual_crop)
            cv2.imwrite(manual_file, manual_crop)
            print(f"[MANUAL SAVE] Manual crop saved as {manual_file}")
            manual_pts = []
 
    key = cv2.waitKey(10) & 0xFF
    if key == ord('m'):
        print("Click and drag to draw cropping box manually...")
        cv2.setMouseCallback("Detected Contours", draw_manual)
    elif key == 27:
        break
 
    time.sleep(0.01)  # Slight delay to reduce CPU usage
 
cap.release()
cv2.destroyAllWindows()


OR (Static code 2)

cmd: py -m pip install pymupdf
or pip install pymupdf
     m pip install opencv-python


import fitz  # PyMuPDF
import cv2
import numpy as np

pdf = fitz.open("252611101100001.pdf")
page = pdf[0]  # first page
pix = page.get_pixmap()

img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)

cv2.imshow("PDF Page", img)
cv2.waitKey(0)
cv2.destroyAllWindows()



            `;


                    var text9 = `# 4_Virtual Drawing using finger tracking 

cmd:
pip install opencv-python 
pip install opencv-python mediapipe
or
pip install mediapipe --user

import cv2
import mediapipe as mp

# Initialize MediaPipe Hand Detector
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

hands = mp_hands.Hands(max_num_hands=1)
cap = cv2.VideoCapture(0)

# Canvas for drawing
canvas = None

while True:
    success, frame = cap.read()
    if not success:
        break

    frame = cv2.flip(frame, 1)

    # Create canvas first time
    if canvas is None:
        canvas = frame.copy() * 0

    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)

    if results.multi_hand_landmarks:
        hand = results.multi_hand_landmarks[0]

        # Get index finger tip: landmark 8
        h, w, c = frame.shape
        x = int(hand.landmark[8].x * w)
        y = int(hand.landmark[8].y * h)

        # Draw circle on fingertip
        cv2.circle(frame, (x, y), 8, (0, 0, 255), -1)

        # Draw on canvas
        cv2.circle(canvas, (x, y), 8, (0, 0, 255), -1)

        mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)

    # Combine drawing with camera
    output = cv2.add(frame, canvas)

    cv2.imshow("Virtual Drawing", output)

    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit
        break

cap.release()
cv2.destroyAllWindows()


OR (Static code)

cmd install:-m pip install opencv-python 

import cv2
import numpy as np

# Load image
img = cv2.imread("C:/Users/Administrator/Downloads/input.png")
canvas = np.zeros_like(img)

# Convert to HSV
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

# Masks for green and blue
green_mask = cv2.inRange(hsv, np.array([40,70,70]), np.array([80,255,255]))
blue_mask = cv2.inRange(hsv, np.array([100,150,50]), np.array([140,255,255]))

# Draw single dot for green
green_points = np.column_stack(np.where(green_mask > 0))
if len(green_points) > 0:
    y, x = green_points[0]  # pick first point (tip)
    cv2.circle(canvas, (x, y), 20, (0,255,0), -1)

# Draw single dot for blue
blue_points = np.column_stack(np.where(blue_mask > 0))
if len(blue_points) > 0:
    y, x = blue_points[0]
    cv2.circle(canvas, (x, y), 20, (255,0,0), -1)

# Merge and show
output = cv2.addWeighted(img, 0.7, canvas, 0.7, 0)
cv2.imshow("Virtual Drawing", output)
cv2.waitKey(0)
cv2.destroyAllWindows()



            `;

                    var text10 = `#5(A)  Multi-Face and object Detection(Group Photo-classify girls and boys ) 


CMD: pip install opencv-python
or install:-m pip install opencv-python
#Download this image - https://www.gettyimages.in/detail/news-photo/actors-daniel-radcliffe-emma-watson-and-rupert-grant-on-the-news-photo/2178972456?adppopup=true

import cv2
import numpy as np

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Load the image
image = cv2.imread('harry1.jpg')

# Check if the image was loaded successfully
if image is None:
    print("Error: Could not load the image 'group_photo.jpg'. Check the filename and path.")
    # You can also check if the cascade loaded, although it rarely fails if the path is correct.
    if face_cascade.empty():
        print("Error: Could not load the Haar Cascade XML file. Check path.")
    exit()

# It's good practice to resize large images for faster processing, uncomment if needed
# scale_factor = 0.5
# image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor)

# Add vertical padding (This is now less necessary since bounding boxes are drawn on the face)
top_padding = 50
padded_image = cv2.copyMakeBorder(image, top_padding, 0, 0, 0, cv2.BORDER_CONSTANT, value=(255, 255, 255))

# Convert to grayscale (essential for Haar Cascade)
gray = cv2.cvtColor(padded_image, cv2.COLOR_BGR2GRAY)

# --- 2. Perform Face Detection ---
# The detectMultiScale function is the core of face detection.
faces = face_cascade.detectMultiScale(
    gray,
    scaleFactor=1.1,     # How much the image size is reduced at each image scale
    minNeighbors=5,      # How many neighbors each candidate rectangle should have
    minSize=(30, 30),    # Minimum possible object size. Objects smaller than this are ignored.
    flags=cv2.CASCADE_SCALE_IMAGE
)

# --- 3. Labeling Logic ---
# Note: Haar Cascades only detect faces; they DO NOT determine gender.
# For demonstration, we will assign your predetermined tags based on the detection order.
name_tags = ["Male", "Female", "Male"] # Increased the list size
object_count = 0

# The 'faces' variable now holds the list of detected bounding boxes (x, y, w, h)
for (x, y, w, h) in faces:
    
    # 1. Draw the Bounding Box
    cv2.rectangle(padded_image, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # 2. Assign Name Tag (Assumes faces are sorted and match the name_tags list)
    tag = name_tags[object_count] if object_count < len(name_tags) else f"Object {object_count + 1}"

    # 3. Calculate Text Position and Size
    font_scale = 0.5
    font_thickness = 2
    font = cv2.FONT_HERSHEY_SIMPLEX
    (text_width, text_height), _ = cv2.getTextSize(tag, font, font_scale, font_thickness)
    
    # Position the text slightly above the bounding box
    text_x = max(2, x)
    text_y = max(20, y - 10) 

    # 4. Draw Background for Text
    cv2.rectangle(padded_image,
                  (text_x - 2, text_y - text_height - 4),
                  (text_x + text_width + 2, text_y),
                  (255, 255, 255), -1)

    # 5. Draw the Text
    cv2.putText(padded_image, tag, (text_x, text_y), font, font_scale, (0, 100, 255), font_thickness)

    object_count += 1

print(f"Detected and labeled {object_count} faces.")
print("--- DISPLAY AND SAVE ---")

# 1. Save the result image
cv2.imwrite('labeled_group_photo.jpg', padded_image)
print("Result saved as 'labeled_group_photo.jpg'")

# 2. Display the result image in a window
cv2.imshow('Face Detector', padded_image)

# Wait indefinitely until a key is pressed (0 means wait forever)
cv2.waitKey(0)

# Destroy all the windows created by OpenCV
cv2.destroyAllWindows()

            `;


                    var text11 = `# 5 (B)  Group Photo-with Person name Detection 


CMD: pip install opencv-python
or install:-m pip install opencv-python

#Download this image - https://www.gettyimages.in/detail/news-photo/actors-daniel-radcliffe-emma-watson-and-rupert-grant-on-the-news-photo/2178972456?adppopup=true

import cv2

# Load image
img = cv2.imread("harry2.jpg")  # image
if img is None:
    print("Error: Image not found!")
    exit()

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Use OpenCV's built-in Haar cascade for face detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Detect faces
faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

# Manually assign names for demonstration (order must match detected faces)
names = ["Ron", "Hermione", "Harry"]  # Adjust according to your photo

# Loop through faces
for i, (x, y, w, h) in enumerate(faces):
    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
    
    # Assign a name from the list, or "Unknown" if not enough names
    name = names[i] if i < len(names) else "Unknown"
    
    cv2.putText(img, name, (x, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

# Show result
cv2.imshow("Group Photo Labeling", img)
cv2.waitKey(0)
cv2.destroyAllWindows()

            `;


                    var text12 = `# 5 (C)  Detect and label common object(like eraser,scale,pencil) in a static image using opencv

#download this image - https://www.shutterstock.com/image-vector/stationery-items-isolated-vector-illustration-on-754395457?trackingId=cad3cc57-ddd5-4184-b16d-c4e89953e419

CMD: pip install opencv-python
install:-m pip install opencv-python

import cv2
import numpy as np

# Load the image
image = cv2.imread('pen.jpeg')

# Check if the image was loaded successfully
if image is None:
    print("Error: Could not load the image. Check the filename and path.")
    exit()

# Add vertical padding at the top (e.g., 50 pixels)
top_padding = 50
padded_image = cv2.copyMakeBorder(image, top_padding, 0, 0, 0, cv2.BORDER_CONSTANT, value=(255, 255, 255))

# Convert to grayscale and blur
gray = cv2.cvtColor(padded_image, cv2.COLOR_BGR2GRAY)
blurred = cv2.GaussianBlur(gray, (5, 5), 0)

# Threshold (inverted binary)
# The use of THRESH_OTSU helps automatically find the best threshold value.
_, thresh = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# Find contours
# RETR_EXTERNAL retrieves only the outermost contours (the objects themselves).
contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Sort contours top-to-bottom then left-to-right
def sort_contours(cnts):
    # Get bounding boxes: (x, y, w, h)
    bounding_boxes = [cv2.boundingRect(c) for c in cnts]
    # Sort based on y-coordinate (for rows) then x-coordinate (for left-to-right order)
    return [cnt for _, cnt in sorted(zip(bounding_boxes, cnts), key=lambda b: (b[0][1], b[0][0]))]

contours = sort_contours(contours)

# Define name tags (Ensure the number of tags matches the expected number of objects)
#name_tags = ["Eraser", "Sharpener", "Scale", "Pencil"]
name_tags = ["Scale", "Pencil", "Eraser"]
min_area = 500  # Minimum contour area to filter out small noise/speckles
object_count = 0

for cnt in contours:
    if cv2.contourArea(cnt) > min_area:
        x, y, w, h = cv2.boundingRect(cnt)
        
        # 1. Draw the Bounding Box
        cv2.rectangle(padded_image, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # 2. Assign Name Tag
        tag = name_tags[object_count] if object_count < len(name_tags) else f"Object {object_count + 1}"

        # 3. Calculate Text Position and Size
        font_scale = 0.5
        font_thickness = 2
        font = cv2.FONT_HERSHEY_SIMPLEX
        (text_width, text_height), _ = cv2.getTextSize(tag, font, font_scale, font_thickness)
        
        # Position the text slightly above the bounding box (y - 10)
        # We use max(2, ...) to ensure the text doesn't go off the left edge (x) or top edge (y)
        text_x = max(2, x)
        text_y = max(20, y - 10) 

        # 4. Draw Background for Text (for better readability)
        cv2.rectangle(padded_image,
                      (text_x - 2, text_y - text_height - 4),
                      (text_x + text_width + 2, text_y),
                      (255, 255, 255), -1) # -1 means fill the rectangle

        # 5. Draw the Text
        # The color (0, 100, 255) is an orange/yellow hue (BGR)
        cv2.putText(padded_image, tag, (text_x, text_y), font, font_scale, (0, 100, 255), font_thickness)

        object_count += 1

# --- DISPLAY AND SAVE FOR LOCAL ENVIRONMENT ---

# 1. Save the result image
cv2.imwrite('labeled_padded_stationery.jpg', padded_image)
print("Result saved as 'labeled_padded_stationery.jpg'")

# 2. Display the result image in a window
# (This is the replacement for cv2_imshow)
cv2.imshow('Labeled Stationery', padded_image)

# Wait indefinitely until a key is pressed (0 means wait forever)
# This is crucial for cv2.imshow to work and keep the window open.
cv2.waitKey(0)

# Destroy all the windows created by OpenCV
cv2.destroyAllWindows()


OR ---- CODE 2 (Static Code)
# Note: make sure that your downloaded file name is pencil.jpg or eraser.jpg or scale.jpg

import cv2
import numpy as np

# Load main image
img = cv2.imread("pencil.jpg")
if img is None:
    print("Error: Main image not found!")
    exit()
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# List of templates and labels
templates = {
    "pencil": "pencil.jpg",
    "eraser": "eraser.jpg",
    "scale": "scale.jpg"
}

threshold = 0.7

for label, template_file in templates.items():
    template = cv2.imread(template_file, 0)
    if template is None:
        print(f"Error: Template '{template_file}' not found!")
        continue

    w, h = template.shape[::-1]
    res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)
    loc = np.where(res >= threshold)

    for pt in zip(*loc[::-1]):
        cv2.rectangle(img, pt, (pt[0]+w, pt[1]+h), (0,255,0), 2)
        cv2.putText(img, label, (pt[0], pt[1]-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)

cv2.imshow("Detected Objects", img)
cv2.waitKey(0)
cv2.destroyAllWindows()
            `;



                    var text13 = `# 6_Triangle-PYOpenGL & GLUT 

#Write a program use PYOpenGL and GLUT TO draw simple triangle

CMD: 
pip install pygame
pip install PyOpenGL
pip install PyOpenGL_accelerate


            `;


                    var text14 = `#7_Square-PYOpenGL & GLUT 
#Write a program use PYOpenGL and GLUT TO draw simple square

CMD: 
pip install pygame
pip install PyOpenGL
pip install PyOpenGL_accelerate

from OpenGL.GL import *
from OpenGL.GLUT import *
from OpenGL.GLU import *

w,h = (500,500)

def square():
    glBegin(GL_QUADS)
    glVertex2f(100,100)
    glVertex2f(200,100)
    glVertex2f(200,200)
    glVertex2f(100,200)
    glEnd()

def iterate():
    glViewport(0,0,500,500)
    glMatrixMode(GL_PROJECTION)
    glLoadIdentity()
    glOrtho(0.0,500,0.0,500,0.0,1.0)
    glMatrixMode(GL_MODELVIEW)
    glLoadIdentity()

def showscreen():
    glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT) #Clear Screen
    glLoadIdentity()
    iterate()
    glColor(1.0,0.0,3.0)
    square()
    glutSwapBuffers()

glutInit() #Initializing window
glutInitDisplayMode(GLUT_RGBA|GLUT_DOUBLE|GLUT_DEPTH) #RGB Mode
glutInitWindowSize(400,400) #Window size
glutInitWindowPosition(100,100) #Window position
glutCreateWindow(b'PyOpen Example - Surabhi Maydeo') #window name
glutDisplayFunc(showscreen) # set display call back
glutMainLoop() # start event loop

            `;


                    var text15 = `#8_3DCube-PYOpenGl
 
#Write a program with PYOpenGL to draw 3d cubes

CMD: 
pip install pygame
pip install PyOpenGL
pip install PyOpenGL_accelerate

import pygame
from pygame.locals import *
from OpenGL.GL import *
from OpenGL.GLU import *

# Vertices
v = (
    (1, -1, -1),
    (1, 1, -1),
    (-1, 1, -1),
    (-1, -1, -1),
    (1, -1, 1),
    (1, 1, 1),
    (-1, -1, 1),
    (-1, 1, 1)
)

# Edges
E = (
    (0, 1), (0, 3), (0, 4),
    (2, 1), (2, 3), (2, 7),
    (6, 3), (6, 4), (6, 7),
    (5, 1), (5, 4), (5, 7)
)

def cube():
    glBegin(GL_LINES)
    for e1 in E:
        for v1 in e1:  # FIXED
            glVertex3fv(v[v1])
    glEnd()
def main():
    pygame.init()
    display = (800, 600)
    pygame.display.set_mode(display, DOUBLEBUF | OPENGL)
    # Setup Projection
    glMatrixMode(GL_PROJECTION)
    gluPerspective(45, (display[0] / display[1]), 0.1, 50.0)
    # Switch to ModelView
    glMatrixMode(GL_MODELVIEW)
    glLoadIdentity()
    glTranslatef(0.0, 0.0, -5)
    while True:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:  # FIXED
                pygame.quit()
                quit()

        # Rotate cube
        glRotatef(1, 3, 1, 1)

        # Clear screen and depth buffer
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
        cube()

        pygame.display.flip()
        pygame.time.wait(20)
main()

            `;


                   

            function copyText(text) {
                navigator.clipboard.writeText(text).then(function () {
                    document.getElementById('copiedMsg').innerHTML = "Text Copied"
                }).catch(function (err) {
                    console.error('Unable to copy text', err);
                });
            }
            </script>

            </body>

            </html>
